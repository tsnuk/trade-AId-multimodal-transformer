# =============================================================================
# EXAMPLE 1: BASIC MULTIMODAL INPUT SCHEMAS
# =============================================================================
# This configuration demonstrates 4 different modalities from a single data file.
# Each modality extracts different information and applies different processing.
#
# Modalities demonstrated:
# 1. Stock Prices (close prices with scaling)
# 2. Price Changes (percentage changes with binning)
# 3. Time Information (hour of day)
# 4. Day of Week (categorical day information)
#
# This setup shows how the same data source can be used to create multiple
# modalities with different representations and processing pipelines.

# =============================================================================
# MODALITY DEFINITIONS
# =============================================================================
modalities:
  # -------------------------------------------------------------------------
  # MODALITY 1: STOCK CLOSE PRICES
  # -------------------------------------------------------------------------
  # Raw price data with scaling to control vocabulary size
  - modality_name: "Stock Prices"
    path: "./examples/sample_data/basic_multimodal/sample_stock_data.csv"
    column_number: 13  # Close price column
    has_header: true
    processing_steps:
      # Scale prices to 2 whole digits and 1 decimal place (e.g., 12.3)
      - function: range_numeric_data
        args:
          num_whole_digits: 2
          decimal_places: 1
        enabled: true
    cross_attention: true  # This modality can attend to others
    randomness_size: null

  # -------------------------------------------------------------------------
  # MODALITY 2: PRICE CHANGES (PERCENTAGES)
  # -------------------------------------------------------------------------
  # Convert prices to percentage changes and bin them into categories
  - modality_name: "Price Changes (%)"
    path: "./examples/sample_data/basic_multimodal/sample_stock_data.csv"
    column_number: 13  # Same price column, different processing
    has_header: true
    processing_steps:
      # First convert to percentage changes
      - function: calculate_percent_changes
        args: {}
        enabled: true
      # Then bin the percentages into 5 categories
      - function: bin_numeric_data
        args:
          num_bins: 5
          outlier_percentile: 0.1
        enabled: true
    cross_attention: false  # This modality doesn't attend to others
    randomness_size: null

  # -------------------------------------------------------------------------
  # MODALITY 3: TIME INFORMATION
  # -------------------------------------------------------------------------
  # Hour of day information (9, 10, 11, etc.)
  - modality_name: "Hour of Day"
    path: "./examples/sample_data/basic_multimodal/sample_stock_data.csv"
    column_number: 6   # Hour column
    has_header: true
    processing_steps: []  # No processing needed - hours are already good integers
    cross_attention: false  # Time doesn't need to attend to other modalities
    randomness_size: null

  # -------------------------------------------------------------------------
  # MODALITY 4: DAY OF WEEK
  # -------------------------------------------------------------------------
  # Day of week information (1=Monday, 2=Tuesday, etc.)
  - modality_name: "Day of Week"
    path: "./examples/sample_data/basic_multimodal/sample_stock_data.csv"
    column_number: 5   # Day of week column
    has_header: true
    processing_steps: []  # No processing needed - day numbers are perfect as-is
    cross_attention: false  # Day of week is independent
    randomness_size: null

# =============================================================================
# CONFIGURATION NOTES FOR BEGINNERS
# =============================================================================
#
# Key concepts demonstrated:
#
# 1. MULTIPLE MODALITIES FROM ONE SOURCE:
#    All 4 modalities use the same CSV file but extract different columns.
#    This shows how to create rich multimodal representations from single datasets.
#
# 2. PROCESSING PIPELINES:
#    - Modality 1: Scales numeric data to control vocabulary size
#    - Modality 2: Converts to percentages then bins for categorization
#    - Modalities 3&4: Use raw data (no processing needed)
#
# 3. CROSS-ATTENTION PATTERNS:
#    - Stock Prices (modality 1): Can attend to all others (learns relationships)
#    - Other modalities: Don't attend (simpler, more focused learning)
#
# 4. DATA ALIGNMENT:
#    Since all modalities use the same file, they are perfectly time-aligned.
#    Each row represents the same 10-minute time period across all modalities.
#
# 5. VOCABULARY SIZES:
#    - Stock Prices: ~50-100 unique scaled values
#    - Price Changes: 5 bins (categories 0-4)
#    - Hour of Day: ~7 unique hours (9-16)
#    - Day of Week: 7 unique days (1-7)
#
# This creates a balanced multimodal system where the model can learn:
# - Price patterns and trends
# - Directional movement categories
# - Time-of-day effects
# - Day-of-week seasonality
#
# Perfect for understanding multimodal transformer basics!